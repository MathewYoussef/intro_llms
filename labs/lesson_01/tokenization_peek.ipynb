{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5d1c5546-1f58-45b4-b4b1-44fe53d7035c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: Cyanobacteria produce photoprotective pigments\n",
      "Token IDs: [1067, 10978, 70475, 9470, 7024, 25227, 67532, 95592]\n",
      "Tokens: ['C', 'yan', 'obacteria', 'Ġproduce', 'Ġphot', 'oprote', 'ctive', 'Ġpigments']\n",
      "Decoded back: Cyanobacteria produce photoprotective pigments\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\n",
    "    \"nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "text = \"Cyanobacteria produce photoprotective pigments\"\n",
    "enc = tok(text)\n",
    "\n",
    "print(\"Text:\", text)\n",
    "print(\"Token IDs:\", enc[\"input_ids\"])\n",
    "print(\"Tokens:\", tok.convert_ids_to_tokens(enc[\"input_ids\"]))\n",
    "print(\"Decoded back:\", tok.decode(enc[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0b75df34-b9c2-4515-a4ae-767d6c9ef086",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notice that not every word is a token and not every token is a word,\n",
    "# sometimes weird word combiantion are a token and sometimes\n",
    "# only a letter or part of a word is a token\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ec667bc9-a153-4bf2-b5fa-8e7b3eaf6505",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A tokenizer is that converts text to token ID's that the model\n",
    "# operates on\n",
    "# Autotokenizer is a transformers helper that\n",
    "# automatically loads the correct tokenizer\n",
    "# class and files for a given model so we dont have to know what the tokenizer class is\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "21b2ca8d-6d4f-464e-a6f8-b402e92faf31",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Last Lab we spent some time discussing eos. \n",
    "# Here we will force the model to stop unexpectedly by setting \n",
    "# eos to be a specific token of our choice, running the model with high\n",
    "# probability of producing that token as an output,\n",
    "# and observe\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "af2bd7c9-d22a-4b12-a04c-b17ed1be0d57",
   "metadata": {},
   "outputs": [],
   "source": [
    "# First, lets identify the token associated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "debda90a-e7dc-4f60-9cc5-1cc81594551a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Text: cell\n",
      "Token IDs: [19187]\n",
      "Tokens: ['cell']\n",
      "Decoded back: cell\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoTokenizer\n",
    "\n",
    "tok = AutoTokenizer.from_pretrained(\n",
    "    \"nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\",\n",
    "    trust_remote_code=True\n",
    ")\n",
    "\n",
    "text = \"cell\"\n",
    "enc = tok(text)\n",
    "\n",
    "print(\"Text:\", text)\n",
    "print(\"Token IDs:\", enc[\"input_ids\"])\n",
    "print(\"Tokens:\", tok.convert_ids_to_tokens(enc[\"input_ids\"]))\n",
    "print(\"Decoded back:\", tok.decode(enc[\"input_ids\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c57ab20d-6944-43b0-842c-b9ff1b55bd6b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# the word cell is luckily one token long. Another key \n",
    "# word like scytonemin, if you look, is four!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "78e9a678-cc62-44de-9478-2ad212af5bbc",
   "metadata": {},
   "outputs": [],
   "source": [
    "# We can take a look again at the special tokens \n",
    "# associated with our model currently: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5fdd0e33-1bfd-482c-a159-fb4daacc95bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "#load model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "eacea0b5-409c-4e2b-9962-3199d64388f1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ce0c7eb4f0e444468e774b6656f44eaa",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Loading checkpoint shards:   0%|          | 0/13 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded tokenizer + model on cuda:0\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoTokenizer, AutoModelForCausalLM\n",
    "\n",
    "model_id = \"nvidia/NVIDIA-Nemotron-3-Nano-30B-A3B-BF16\"\n",
    "revision = \"2e43387afd60157064e5bef4e9a583f887c6dfdd\"  # your cached snapshot\n",
    "cache_dir = \"/data/hf/hub\"\n",
    "\n",
    "tokenizer = AutoTokenizer.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    use_fast=True,\n",
    "    revision=revision,\n",
    "    cache_dir=cache_dir,\n",
    "    local_files_only=True,\n",
    ")\n",
    "\n",
    "model = AutoModelForCausalLM.from_pretrained(\n",
    "    model_id,\n",
    "    trust_remote_code=True,\n",
    "    dtype=torch.bfloat16,\n",
    "    device_map=\"cuda:0\",\n",
    "    revision=revision,\n",
    "    cache_dir=cache_dir,\n",
    "    local_files_only=True,\n",
    ")\n",
    "\n",
    "print(\"Loaded tokenizer + model on\", model.device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "78358a12-3fd8-4acd-bc54-b43bf7b86787",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tokenizer.eos_token      = <|im_end|>\n",
      "tokenizer.eos_token_id   = 11\n",
      "generation eos_token_id  = [2, 11]\n",
      "2 '</s>'\n",
      "11 '<|im_end|>'\n"
     ]
    }
   ],
   "source": [
    "tokenizer.eos_token, tokenizer.eos_token_id,\n",
    "model.generation_config.eos_token_id\n",
    "\n",
    "print(\"tokenizer.eos_token      =\", tokenizer.eos_token)\n",
    "print(\"tokenizer.eos_token_id   =\", tokenizer.eos_token_id)\n",
    "print(\"generation eos_token_id  =\", model.generation_config.eos_token_id)\n",
    "\n",
    "for tid in model.generation_config.eos_token_id:\n",
    "    print(tid, repr(tokenizer.decode([tid], skip_special_tokens=False)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "96bb5fd8-b04e-4541-8d15-b39603191c64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "## Cyanobacterial Photoprotection – How Prokaryotes Keep Their Light‑Harvest Machinery Safe  \n",
      "\n",
      "Cyanobacteria are photoautotrophic bacteria that live at the interface of light and water, where they must harvest photons for photosynthesis while avoiding the damaging effects of excess excitation energy (EEE).  Unlike eukaryotes whose photosynthetic apparatus is housed inside chloroplasts bounded by double membranes, cyanobacteria have their photosystems embedded directly into **a single, continuous plasma membrane** that also contains all other essential bioenergetic complexes (respiratory chains, transporters, etc.). This “prokaryotic” organization imposes unique constraints on how protective strategies can be assembled, deployed, and coordinated.\n",
      "\n",
      "Below we walk through the main photoprotective pathways that cyanobacteria employ, linking each mechanism back to its structural context within the cell envelope. The focus is always on *how* the architecture—a lipid bilayer dotted with pigment–protein complexes—enables or limits those defenses.\n",
      "\n",
      "---\n",
      "\n",
      "### 1. Core Photosystem Architecture & Its Vulnerabilities  \n",
      "\n",
      "| Feature | Location in Cell | Functional Role |\n",
      "|---------|------------------|-----------------|\n",
      "| **Photosystem II (PSII) core complex + antennae** | Thylako\n"
     ]
    }
   ],
   "source": [
    "messages = [{\"role\": \"user\", \"content\": \"Describe cyanobacteria photoprotective mechanisms in relation to practecting  the prokaryotic system. Contained in a phospholipid bilayer\"}]\n",
    "\n",
    "input_ids = tokenizer.apply_chat_template(\n",
    "    messages,\n",
    "    tokenize=True,\n",
    "    enable_thinking=False, #on by default in nemotron\n",
    "    add_generation_prompt=True,\n",
    "    return_tensors=\"pt\",\n",
    ").to(model.device)\n",
    "\n",
    "with torch.inference_mode():\n",
    "    out = model.generate(\n",
    "        input_ids,\n",
    "        max_new_tokens=250,\n",
    "        min_new_tokens=40,\n",
    "        do_sample=True, \n",
    "        temperature=0.8,\n",
    "        top_k=15, \n",
    "        top_p=0.9, \n",
    "        repetition_penalty=1.2,\n",
    "        eos_token_id=19187, #token for cell\n",
    "        pad_token_id=tokenizer.eos_token_id,\n",
    "    )\n",
    "\n",
    "prompt_len = input_ids.shape[-1]\n",
    "gen_ids = out[0, prompt_len:].detach().to(\"cpu\").tolist() \n",
    "print(tokenizer.decode(gen_ids, skip_special_tokens=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "26b10df5-348a-4289-a2c9-c8ab7d4bccca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# This experiemnt proivides valuable isnight. Setting eos, \n",
    "# we command \" stop if the token 1987 is proiduced\" not \"stop\n",
    "# if the word 'cell' is produced\n",
    "# token is the fundamental unit, and as we have seen,\n",
    "# even thought he word cell is present in our output\n",
    "# it is not associated with the token ID of \"cell\"- which can be produced by different token ID's"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9207535b-8ee7-47c3-a48c-0ba9066cce73",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
